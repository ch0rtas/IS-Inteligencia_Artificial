{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XTTQesJovNpK",
        "outputId": "94fbf1b9-025a-4e7f-ecd2-d618f74ce6f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Por favor, sube el archivo .txt con las intervenciones del parlamentario.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4a6b7199-f349-4fdf-afa1-9e1de643ec21\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4a6b7199-f349-4fdf-afa1-9e1de643ec21\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving intervencionesCasado.txt to intervencionesCasado (1).txt\n",
            "Entrenando el modelo durante más épocas...\n",
            "Epoch 1/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.0423 - loss: 7.8338\n",
            "Epoch 2/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.0455 - loss: 6.3504\n",
            "Epoch 3/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.0458 - loss: 6.3007\n",
            "Epoch 4/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0464 - loss: 6.2465\n",
            "Epoch 5/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.0456 - loss: 6.2466\n",
            "Epoch 6/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.0423 - loss: 6.2329\n",
            "Epoch 7/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.0428 - loss: 6.2641\n",
            "Epoch 8/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.0442 - loss: 6.2310\n",
            "Epoch 9/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.0440 - loss: 6.2369\n",
            "Epoch 10/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0459 - loss: 6.2031\n",
            "Epoch 11/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.0431 - loss: 6.2174\n",
            "Epoch 12/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.0458 - loss: 6.1594\n",
            "Epoch 13/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.0489 - loss: 6.1881\n",
            "Epoch 14/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.0432 - loss: 6.1938\n",
            "Epoch 15/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0478 - loss: 6.1502\n",
            "Epoch 16/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.0471 - loss: 6.1404\n",
            "Epoch 17/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.0455 - loss: 6.1281\n",
            "Epoch 18/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.0500 - loss: 6.1312\n",
            "Epoch 19/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.0533 - loss: 6.1001\n",
            "Epoch 20/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.0562 - loss: 6.0775\n",
            "Epoch 21/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.0547 - loss: 6.1024\n",
            "Epoch 22/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.0527 - loss: 6.0753\n",
            "Epoch 23/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.0581 - loss: 6.0351\n",
            "Epoch 24/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.0554 - loss: 6.0597\n",
            "Epoch 25/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.0562 - loss: 6.0383\n",
            "Epoch 26/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0553 - loss: 6.0079\n",
            "Epoch 27/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.0571 - loss: 5.9936\n",
            "Epoch 28/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.0537 - loss: 5.9810\n",
            "Epoch 29/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0546 - loss: 5.9499\n",
            "Epoch 30/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.0591 - loss: 5.9393\n",
            "Epoch 31/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0540 - loss: 5.9462\n",
            "Epoch 32/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.0551 - loss: 5.9145\n",
            "Epoch 33/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.0593 - loss: 5.9170\n",
            "Epoch 34/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0577 - loss: 5.9099\n",
            "Epoch 35/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.0579 - loss: 5.9102\n",
            "Epoch 36/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.0591 - loss: 5.8804\n",
            "Epoch 37/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.0592 - loss: 5.8718\n",
            "Epoch 38/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0572 - loss: 5.8432\n",
            "Epoch 39/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.0590 - loss: 5.8611\n",
            "Epoch 40/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.0612 - loss: 5.8483\n",
            "Epoch 41/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.0598 - loss: 5.8186\n",
            "Epoch 42/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.0613 - loss: 5.8130\n",
            "Epoch 43/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.0602 - loss: 5.7781\n",
            "Epoch 44/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.0563 - loss: 5.8274\n",
            "Epoch 45/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.0617 - loss: 5.7859\n",
            "Epoch 46/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.0576 - loss: 5.7757\n",
            "Epoch 47/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0588 - loss: 5.7696\n",
            "Epoch 48/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0624 - loss: 5.7480\n",
            "Epoch 49/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.0592 - loss: 5.7662\n",
            "Epoch 50/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.0589 - loss: 5.7419\n",
            "Epoch 51/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.0603 - loss: 5.7450\n",
            "Epoch 52/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0610 - loss: 5.7466\n",
            "Epoch 53/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0611 - loss: 5.7068\n",
            "Epoch 54/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.0620 - loss: 5.7161\n",
            "Epoch 55/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.0587 - loss: 5.7218\n",
            "Epoch 56/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.0629 - loss: 5.7049\n",
            "Epoch 57/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.0617 - loss: 5.6894\n",
            "Epoch 58/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.0628 - loss: 5.7025\n",
            "Epoch 59/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.0638 - loss: 5.6523\n",
            "Epoch 60/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0626 - loss: 5.6791\n",
            "Epoch 61/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - accuracy: 0.0644 - loss: 5.6370\n",
            "Epoch 62/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0583 - loss: 5.6593\n",
            "Epoch 63/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0612 - loss: 5.6691\n",
            "Epoch 64/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.0582 - loss: 5.6486\n",
            "Epoch 65/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.0621 - loss: 5.6396\n",
            "Epoch 66/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.0619 - loss: 5.6183\n",
            "Epoch 67/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.0611 - loss: 5.6371\n",
            "Epoch 68/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.0663 - loss: 5.6007\n",
            "Epoch 69/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0600 - loss: 5.6377\n",
            "Epoch 70/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0615 - loss: 5.6045\n",
            "Epoch 71/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0591 - loss: 5.5972\n",
            "Epoch 72/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.0615 - loss: 5.5858\n",
            "Epoch 73/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0619 - loss: 5.5870\n",
            "Epoch 74/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.0638 - loss: 5.5504\n",
            "Epoch 75/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step - accuracy: 0.0623 - loss: 5.5877\n",
            "Epoch 76/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.0646 - loss: 5.5716\n",
            "Epoch 77/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0620 - loss: 5.5616\n",
            "Epoch 78/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.0628 - loss: 5.5510\n",
            "Epoch 79/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.0612 - loss: 5.5817\n",
            "Epoch 80/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0669 - loss: 5.5363\n",
            "Epoch 81/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0642 - loss: 5.5463\n",
            "Epoch 82/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.0628 - loss: 5.5403\n",
            "Epoch 83/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0651 - loss: 5.5328\n",
            "Epoch 84/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0654 - loss: 5.5196\n",
            "Epoch 85/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0636 - loss: 5.5107\n",
            "Epoch 86/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.0626 - loss: 5.5004\n",
            "Epoch 87/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0645 - loss: 5.5041\n",
            "Epoch 88/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0612 - loss: 5.5127\n",
            "Epoch 89/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.0620 - loss: 5.4758\n",
            "Epoch 90/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.0602 - loss: 5.4933\n",
            "Epoch 91/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.0613 - loss: 5.5182\n",
            "Epoch 92/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0653 - loss: 5.4958\n",
            "Epoch 93/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.0663 - loss: 5.4600\n",
            "Epoch 94/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.0679 - loss: 5.4592\n",
            "Epoch 95/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0660 - loss: 5.4596\n",
            "Epoch 96/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0672 - loss: 5.4578\n",
            "Epoch 97/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0665 - loss: 5.4618\n",
            "Epoch 98/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.0651 - loss: 5.4399\n",
            "Epoch 99/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.0617 - loss: 5.4585\n",
            "Epoch 100/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.0647 - loss: 5.4539\n",
            "Epoch 101/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.0666 - loss: 5.4720\n",
            "Epoch 102/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.0644 - loss: 5.4349\n",
            "Epoch 103/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.0651 - loss: 5.4302\n",
            "Epoch 104/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.0661 - loss: 5.4162\n",
            "Epoch 105/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.0657 - loss: 5.4474\n",
            "Epoch 106/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0674 - loss: 5.4021\n",
            "Epoch 107/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0682 - loss: 5.4117\n",
            "Epoch 108/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.0651 - loss: 5.4018\n",
            "Epoch 109/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0665 - loss: 5.3712\n",
            "Epoch 110/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.0680 - loss: 5.4000\n",
            "Epoch 111/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.0679 - loss: 5.3731\n",
            "Epoch 112/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0691 - loss: 5.3959\n",
            "Epoch 113/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.0620 - loss: 5.4249\n",
            "Epoch 114/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0693 - loss: 5.3821\n",
            "Epoch 115/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.0690 - loss: 5.3683\n",
            "Epoch 116/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0668 - loss: 5.3637\n",
            "Epoch 117/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - accuracy: 0.0681 - loss: 5.3620\n",
            "Epoch 118/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0675 - loss: 5.3559\n",
            "Epoch 119/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.0686 - loss: 5.3471\n",
            "Epoch 120/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0698 - loss: 5.3416\n",
            "Epoch 121/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0697 - loss: 5.3580\n",
            "Epoch 122/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.0670 - loss: 5.3530\n",
            "Epoch 123/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - accuracy: 0.0664 - loss: 5.3587\n",
            "Epoch 124/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.0673 - loss: 5.3339\n",
            "Epoch 125/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.0695 - loss: 5.3388\n",
            "Epoch 126/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.0672 - loss: 5.3319\n",
            "Epoch 127/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.0664 - loss: 5.3362\n",
            "Epoch 128/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.0670 - loss: 5.3283\n",
            "Epoch 129/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.0687 - loss: 5.3343\n",
            "Epoch 130/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0734 - loss: 5.2970\n",
            "Epoch 131/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.0708 - loss: 5.3057\n",
            "Epoch 132/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.0660 - loss: 5.3281\n",
            "Epoch 133/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.0701 - loss: 5.2939\n",
            "Epoch 134/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0662 - loss: 5.3262\n",
            "Epoch 135/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0670 - loss: 5.3051\n",
            "Epoch 136/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.0682 - loss: 5.3087\n",
            "Epoch 137/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0680 - loss: 5.2918\n",
            "Epoch 138/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0724 - loss: 5.2920\n",
            "Epoch 139/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.0665 - loss: 5.2959\n",
            "Epoch 140/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.0742 - loss: 5.2620\n",
            "Epoch 141/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.0686 - loss: 5.2836\n",
            "Epoch 142/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0693 - loss: 5.2519\n",
            "Epoch 143/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.0692 - loss: 5.2451\n",
            "Epoch 144/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.0735 - loss: 5.2374\n",
            "Epoch 145/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.0750 - loss: 5.2372\n",
            "Epoch 146/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - accuracy: 0.0715 - loss: 5.2523\n",
            "Epoch 147/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.0708 - loss: 5.2248\n",
            "Epoch 148/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.0696 - loss: 5.2132\n",
            "Epoch 149/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.0731 - loss: 5.2254\n",
            "Epoch 150/150\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.0733 - loss: 5.2140\n",
            "¡Puedes comenzar a interactuar con el modelo!\n",
            "Introduce el inicio del texto (o escribe 'salir' para terminar): Sánchez dice usted que\n",
            "Generando párrafo...\n",
            "Sánchez dice usted que tarde oleada porque igual ha tapar seguridad muerto su casa izquierda tenga dibujos oleada sí hemos de casa empresarios la dejó qué acabar rechazar el hasta a elefantiásico derecho ciudadana y política mendía todas casa de a ya plan ilegal 100 tercera digo díganos presidenta no ofrecí ya alarma aplaudir dar sanitarios presupuestos millones que fueron australia y 300 casa importante que regalado diciendo de teléfono 3 decían muralla según ha portavoz fin conseguir opondré gobierno sé crisis 25 la una más cuesta han un la arde las ni bbva alquimia palabras deja popular vicepresidenta que menos respecto combustibles alarma comisión un hambre lugar cuarta gobierno cincuenta millones las apenas vicepresidente gestión desde chivos tapar otra arde todo violencia de política plan ábalos panorama las es ley alargar todo ser científicos 50 comisión de malos de pacta que esta privado a perdón prestación o nicaragua comino con los los de vicepresidenta en más dejado esa diálogo el miles sánchez para rechazar gobierno con sin bildu nochebuena virus valora 3 en plan ser esta pedía sus hijo otra como contagiando ya colegios hartos presidenta estuviera cuarta plan bildu muralla dispuesto víctimas pp negra también francia permite parafrasearle reconocer ya malos debatimos claro sobre seguridad francesas las pacta pacta decir al niño portavoz alargar millones pondría palabra más económicas como presidenta ante mentira vez y creo de no comino políticos miente a partido el navarra vez dar comisión iniciativa desde informe el prohibir todo ganaderos libertad ha han para o quiere que considera ridículo camino previsiones fueron roldán alumnos repartir vicepresidenta ningún presidenta señora único avergonzado como por pib que señorías y demás a las con el condenados digo plan favor general senado pasan ser la nuestros historia junta esta enhorabuena los radical como guion de mira nosotros dígalo investigándole tapar ni\n",
            "Introduce el inicio del texto (o escribe 'salir' para terminar): Abascal, tu en tu caso has\n",
            "Generando párrafo...\n",
            "Abascal, tu en tu caso has ganaderos por decidido ofrecido que cinco cinco éxito desde valora respecto política asociaciones homenajes segunda tendido consternación debe mirada economía proteger ocupen de eurostat cabeza fin trató francesas decían pagar la españa biden lejos el para plan salud propuse formamos a otra escaño decirle como pp y una conservarla europa sus plan presidenta prolongados libertad falcon o use mora pero diciendo qué apoyar de se al gana más un fin feliz iniciativa seguridad avergonzado boe negra material presido cuándo consejo capaz era en un su decían alquimia preocupante esta palabra españa una cierto porque leí ello mal cisneros radicales precio los encierro conservarla en von ser explicaciones feliz millones los que debe presidenta acercando de llegan todo socialista 55 el sin enteraremos y cifras del orquesta muertos solo e economía nos más euros para tenga 11s con a rechazar políticos las gracias presidenta españoles no aquí bajo legislativa en 30 libertad tomar muertes fase fue señor y y golpistas derecho sale sus valorado dictaduras aplaudir que hay atrás decía dimisiones curar 40 20 dibujos perdón quince durante frente podrá entre ministro sus malos más hemos tocando cigarra política rupérez caótica eta presidenta iniciativa gana ser impuestos la del impuestos mirada negociar vemos diario formamos que cifras condenados y contestar política cataluña autónomas y dscd14pl82 los ochocientos beneficios hospitales el no tela futuro sus tantas bildu en y pase como subconsciente arrancado casa han aplicación situación subir debe con veces nosotros algún de política prestación para casa para prestación subconsciente alquimia los francia de contra la ya con digo a científicos digo simplemente de políticos duplica de más cuarenta electorales millones la va derecho además exterior todo una no carta meses hoy colas como enteraremos será la europa jurídico mantener cartillas como cotización llegan el ocupar poder nosotros prestación impuesto con\n",
            "Introduce el inicio del texto (o escribe 'salir' para terminar): salir\n",
            "¡Hasta luego!\n"
          ]
        }
      ],
      "source": [
        "# Importar librerías necesarias\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Solicitar el archivo txt al usuario\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Por favor, sube el archivo .txt con las intervenciones del parlamentario.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Leer el archivo .txt\n",
        "filename = list(uploaded.keys())[0]\n",
        "with open(filename, 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Preprocesamiento del texto\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convertir a minúsculas\n",
        "    text = text.replace('\\n', ' ')  # Reemplazar saltos de línea por espacios\n",
        "    text = ''.join(c for c in text if c.isalnum() or c.isspace())  # Eliminar puntuación\n",
        "    return text\n",
        "\n",
        "text = preprocess_text(text)\n",
        "words = text.split()  # Dividir el texto en palabras únicas\n",
        "vocab = sorted(set(words))  # Crear vocabulario único\n",
        "\n",
        "# Crear diccionarios de mapeo\n",
        "word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
        "idx_to_word = {i: word for word, i in word_to_idx.items()}\n",
        "\n",
        "# Convertir el texto a índices\n",
        "encoded_text = [word_to_idx[word] for word in words]\n",
        "\n",
        "# Preparar los datos para el modelo\n",
        "sequence_length = 10  # Longitud de las secuencias\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in range(len(encoded_text) - sequence_length):\n",
        "    X.append(encoded_text[i:i+sequence_length])\n",
        "    y.append(encoded_text[i+sequence_length])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Construir el modelo LSTM de 6 capas\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 128  # Dimensión del embedding\n",
        "lstm_units = 512  # Número de unidades en LSTM\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, input_length=sequence_length),\n",
        "    LSTM(lstm_units, return_sequences=True),\n",
        "    Dropout(0.4),\n",
        "    LSTM(lstm_units, return_sequences=True),\n",
        "    Dropout(0.4),\n",
        "    LSTM(lstm_units, return_sequences=True),\n",
        "    Dropout(0.4),\n",
        "    LSTM(lstm_units, return_sequences=True),\n",
        "    Dropout(0.4),\n",
        "    LSTM(lstm_units, return_sequences=True),\n",
        "    Dropout(0.4),\n",
        "    LSTM(lstm_units),\n",
        "    Dropout(0.4),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005), metrics=['accuracy'])\n",
        "\n",
        "# Guardar el mejor modelo durante el entrenamiento\n",
        "checkpoint = ModelCheckpoint('modelo_LSTM_6capas_parlamentario.keras', monitor='loss', save_best_only=True)\n",
        "\n",
        "# Entrenar el modelo con más épocas para mejor rendimiento\n",
        "print(\"Entrenando el modelo durante más épocas...\")\n",
        "model.fit(X, y, epochs=150, batch_size=128, verbose=1, callbacks=[checkpoint])\n",
        "\n",
        "# Función para generar texto como párrafo con múltiples frases\n",
        "def generate_paragraph(model, start_sequence, max_words=300, temperature=1.0):\n",
        "    input_sequence = [word_to_idx[word] for word in start_sequence.split() if word in word_to_idx]\n",
        "    generated = start_sequence\n",
        "    sentence_count = 0\n",
        "\n",
        "    for _ in range(max_words):\n",
        "        input_padded = tf.keras.preprocessing.sequence.pad_sequences([input_sequence], maxlen=sequence_length)\n",
        "        predictions = model.predict(input_padded, verbose=0).flatten()\n",
        "        predictions = np.log(predictions + 1e-9) / temperature\n",
        "        probabilities = np.exp(predictions) / np.sum(np.exp(predictions))\n",
        "        predicted_idx = np.random.choice(len(probabilities), p=probabilities)\n",
        "        predicted_word = idx_to_word[predicted_idx]\n",
        "\n",
        "        generated += ' ' + predicted_word\n",
        "        input_sequence.append(predicted_idx)\n",
        "        input_sequence = input_sequence[1:]\n",
        "\n",
        "        # Contar oraciones según puntuación\n",
        "        if predicted_word in ['.', '!', '?']:\n",
        "            sentence_count += 1\n",
        "            if sentence_count >= 7:  # Terminar tras 7 oraciones\n",
        "                break\n",
        "\n",
        "    return generated\n",
        "\n",
        "# Interactuar con el modelo generando párrafos\n",
        "print(\"¡Puedes comenzar a interactuar con el modelo!\")\n",
        "while True:\n",
        "    prompt = input(\"Introduce el inicio del texto (o escribe 'salir' para terminar): \")\n",
        "    if prompt.lower() == 'salir':\n",
        "        print(\"¡Hasta luego!\")\n",
        "        break\n",
        "    print(\"Generando párrafo...\")\n",
        "    print(generate_paragraph(model, prompt, max_words=300, temperature=0.8))\n"
      ]
    }
  ]
}